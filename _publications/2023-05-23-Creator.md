---
title: "CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasonings of Large Language Models"
collection: publications
permalink: /publication/2023-05-23-Creator
excerpt: 'The paper proposes CREATOR, a novel framework that empowers LLMs to create their own tools through documentation and code realization'
date: 2023-05-23
venue: 'EMNLP 2023 Findings'
paperurl: 'https://arxiv.org/pdf/2305.14318.pdf'
citation: 'Qian, C., Han, C., Fung, Y. R., Qin, Y., Liu, Z., & Ji, H. (2023). CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasonings of Large Language Models. EMNLP 2023 Findings. /abs/2305.14318'
---

Large Language Models (LLMs) have demonstrated significant progress in utilizing external APIs as tools for various tasks. However, their tool-using ability is limited by the availability of suitable APIs and the instability of implicit reasoning, particularly when simultaneously engaging in reasoning about plans and actual calculations. To address these limitations, we propose CREATOR, a novel framework that empowers LLMs to create their own tools through documentation and code realization. CREATOR disentangles the LLM's ability into two distinct phases: abstract tool creation and concrete decision execution, which results in improved LLM performance. We evaluate CREATOR on two established benchmarks: MATH, which consists of challenging math competition problems, and TabMWP, which includes diverse tabular contents for problem-solving. Remarkably, CREATOR significantly outperforms existing chain-of-thought (CoT), program-of-thought (PoT), and tool-using baselines on these two benchmarks. Additionally, we present a new dataset, Creation Challenge, comprising 2K diverse questions, to highlight the necessity and benefits of LLMs' tool creation ability in effectively addressing these problems. Furthermore, our research reveals that leveraging LLMs as tool creators facilitates knowledge transfer, and LLMs exhibit varying levels of tool creation abilities, enabling them to flexibly tackle diverse situations. Our study represents a promising avenue for maximizing the potential of LLMs and advancing toward truly intelligent and adaptable AI systems.

[Download paper here](https://arxiv.org/pdf/2305.14318.pdf)

