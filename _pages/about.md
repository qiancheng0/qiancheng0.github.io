---
permalink: /
title: "Cheng Qian"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

This is Cheng Qian's personal homepage.

## A short introduction
I am an undergraduate student studying at Tsinghua University, majoring in Computer Science and Technology. I am a member of [THUNLP](http://nlp.csai.tsinghua.edu.cn/), advised by [Zhiyuan Liu](http://nlp.csai.tsinghua.edu.cn/~lzy/). My research interests primarily lie in the field of natural language processing, with a particular focus on pre-trained language models, parameter and data-efficient tuning, LLM-based AI agent and tool learning and tool creation of large language models.

In 2023 summer, I worked with [Sherry Wu](https://www.cs.cmu.edu/~sherryw/) on the impacts of external knowledge (e.g. from tools, retrieval, etc.) to parametric knowledge in the newest [paper](http://qiancheng0.github.io/files/Impact_of_EKD_on_PKG.pdf). In previous research, I have investigated the tool creation ability of large language models ([paper](https://arxiv.org/pdf/2305.14318.pdf)), and how the tool-use ability could be adapted to open-source models ([paper](http://qiancheng0.github.io/files/Tune_on_Tool.pdf)). This spring, I have also participated in a survey [paper](https://arxiv.org/pdf/2304.08354.pdf) on tool learning with foundation models.

Previously, I have explored the concept of recycling outdated weights during the lifelong pre-training of LLMs, which was published in ACL 2023 findings ([paper](https://arxiv.org/pdf/2305.08702.pdf)). Additionally, I have contributed to research on the mode connectivity of models' various minima, which was presented at EMNLP 2022 ([paper](https://arxiv.org/pdf/2210.14102.pdf)).

Looking forward, I am seeking a Ph.D. position in NLP, starting from Fall 2024. If you are interested in my research or would like to collaborate, please feel free to reach out to me.

<b>Recent Research Highlights:</b>

* Explore the foundational model's ability of using external tools under various scenarios.
* Propose CREATOR to help automatic tool-creation.
* Adapt tool-using ability to open-source LLaMA models.
* Investigate the impact of external knowledge (e.g. from tools, retrieval, etc.) brought to LLMs.

## Papers
(*indicates equal contribution)

**Cheng Qian**, Xinran Zhao, Sherry Tongshuang Wu. "Merge Conflicts!" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs ([Paper](https://arxiv.org/pdf/2309.08594v1.pdf) / [Code](https://github.com/qiancheng0/EKD_Impacts_PKG))

**Cheng Qian**, Chi Han, Yi R. Fung, Yujia Qin, Zhiyuan Liu, Heng Ji. CREATOR: Disentangling Abstract and Concrete Reasonings of Large Language Models through Tool Creation. ([Paper](https://arxiv.org/pdf/2305.14318.pdf))

**Cheng Qian**, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu. Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model. ([Paper](http://qiancheng0.github.io/files/Tune_on_Tool.pdf))

Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, **Cheng Qian**, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, Maosong Sun. Tool Learning with Foundation Models. Submitted to Nature Machine Intelligence, under review. ([Paper](https://arxiv.org/pdf/2304.08354.pdf) / [Code](https://github.com/OpenBMB/BMTools))

**Cheng Qian**\*, Yujia Qin\*, Yankai Lin, Xu Han, Zhiyuan Liu, Maosong Sun and Jie Zhou. Recyclable Tuning for Continual Pre-training. ACL 2023 findings. ([Paper](https://arxiv.org/pdf/2305.08702.pdf) / [Code](https://github.com/thunlp/RecyclableTuning))

**Cheng Qian**\*, Yujia Qin\*, Jing Yi\*, Weize Chen, Yankai Lin, Xu Han, Zhiyuan Liu, Maosong Sun and Jie Zhou. Exploring Mode Connectivity for Pre-trained Language Models. EMNLP 2022. ([Paper](https://arxiv.org/pdf/2210.14102.pdf) / [Code](https://github.com/thunlp/Mode-Connectivity-PLM))

## For more information
More info about Cheng Qian can be found in [CV](https://qiancheng0.github.io/cv/) or [downloaded CV](http://qiancheng0.github.io/files/CV_ChengQian.pdf).
